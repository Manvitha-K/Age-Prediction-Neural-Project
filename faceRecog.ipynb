{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import os\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def download_landmarks(dst_file):\n",
    "    url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
    "    decompressor = bz2.BZ2Decompressor()\n",
    "    \n",
    "    with urlopen(url) as src, open(dst_file, 'wb') as dst:\n",
    "        data = src.read(1024)\n",
    "        while len(data) > 0:\n",
    "            dst.write(decompressor.decompress(data))\n",
    "            data = src.read(1024)\n",
    "\n",
    "dst_dir = 'models'\n",
    "dst_file = os.path.join(dst_dir, 'landmarks.dat')\n",
    "\n",
    "if not os.path.exists(dst_file):\n",
    "    os.makedirs(dst_dir)\n",
    "    download_landmarks(dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "TEMPLATE = np.float32([\n",
    "    (0.0792396913815, 0.339223741112), (0.0829219487236, 0.456955367943),\n",
    "    (0.0967927109165, 0.575648016728), (0.122141515615, 0.691921601066),\n",
    "    (0.168687863544, 0.800341263616), (0.239789390707, 0.895732504778),\n",
    "    (0.325662452515, 0.977068762493), (0.422318282013, 1.04329000149),\n",
    "    (0.531777802068, 1.06080371126), (0.641296298053, 1.03981924107),\n",
    "    (0.738105872266, 0.972268833998), (0.824444363295, 0.889624082279),\n",
    "    (0.894792677532, 0.792494155836), (0.939395486253, 0.681546643421),\n",
    "    (0.96111933829, 0.562238253072), (0.970579841181, 0.441758925744),\n",
    "    (0.971193274221, 0.322118743967), (0.163846223133, 0.249151738053),\n",
    "    (0.21780354657, 0.204255863861), (0.291299351124, 0.192367318323),\n",
    "    (0.367460241458, 0.203582210627), (0.4392945113, 0.233135599851),\n",
    "    (0.586445962425, 0.228141644834), (0.660152671635, 0.195923841854),\n",
    "    (0.737466449096, 0.182360984545), (0.813236546239, 0.192828009114),\n",
    "    (0.8707571886, 0.235293377042), (0.51534533827, 0.31863546193),\n",
    "    (0.516221448289, 0.396200446263), (0.517118861835, 0.473797687758),\n",
    "    (0.51816430343, 0.553157797772), (0.433701156035, 0.604054457668),\n",
    "    (0.475501237769, 0.62076344024), (0.520712933176, 0.634268222208),\n",
    "    (0.565874114041, 0.618796581487), (0.607054002672, 0.60157671656),\n",
    "    (0.252418718401, 0.331052263829), (0.298663015648, 0.302646354002),\n",
    "    (0.355749724218, 0.303020650651), (0.403718978315, 0.33867711083),\n",
    "    (0.352507175597, 0.349987615384), (0.296791759886, 0.350478978225),\n",
    "    (0.631326076346, 0.334136672344), (0.679073381078, 0.29645404267),\n",
    "    (0.73597236153, 0.294721285802), (0.782865376271, 0.321305281656),\n",
    "    (0.740312274764, 0.341849376713), (0.68499850091, 0.343734332172),\n",
    "    (0.353167761422, 0.746189164237), (0.414587777921, 0.719053835073),\n",
    "    (0.477677654595, 0.706835892494), (0.522732900812, 0.717092275768),\n",
    "    (0.569832064287, 0.705414478982), (0.635195811927, 0.71565572516),\n",
    "    (0.69951672331, 0.739419187253), (0.639447159575, 0.805236879972),\n",
    "    (0.576410514055, 0.835436670169), (0.525398405766, 0.841706377792),\n",
    "    (0.47641545769, 0.837505914975), (0.41379548902, 0.810045601727),\n",
    "    (0.380084785646, 0.749979603086), (0.477955996282, 0.74513234612),\n",
    "    (0.523389793327, 0.748924302636), (0.571057789237, 0.74332894691),\n",
    "    (0.672409137852, 0.744177032192), (0.572539621444, 0.776609286626),\n",
    "    (0.5240106503, 0.783370783245), (0.477561227414, 0.778476346951)])\n",
    "\n",
    "TPL_MIN, TPL_MAX = np.min(TEMPLATE, axis=0), np.max(TEMPLATE, axis=0)\n",
    "MINMAX_TEMPLATE = (TEMPLATE - TPL_MIN) / (TPL_MAX - TPL_MIN)\n",
    "\n",
    "\n",
    "class AlignDlib:\n",
    "   \n",
    "    #: Landmark indices.\n",
    "    INNER_EYES_AND_BOTTOM_LIP = [39, 42, 57]\n",
    "    OUTER_EYES_AND_NOSE = [36,45,33]\n",
    "\n",
    "    def __init__(self, facePredictor):\n",
    "       \n",
    "        assert facePredictor is not None\n",
    "\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor(facePredictor)\n",
    "\n",
    "    def getAllFaceBoundingBoxes(self, rgbImg):\n",
    "        \n",
    "        assert rgbImg is not None\n",
    "\n",
    "        try:\n",
    "            return self.detector(rgbImg, 1)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: {}\".format(e))\n",
    "            # In rare cases, exceptions are thrown.\n",
    "            return []\n",
    "\n",
    "    def getLargestFaceBoundingBox(self, rgbImg, skipMulti=False):\n",
    "       \n",
    "        assert rgbImg is not None\n",
    "\n",
    "        faces = self.getAllFaceBoundingBoxes(rgbImg)\n",
    "        #print(\"total faces {}\".format(len(faces)))\n",
    "        #return faces\n",
    "        \n",
    "        \n",
    "        if (not skipMulti and len(faces) > 0) or len(faces) == 1:\n",
    "            return max(faces, key=lambda rect: rect.width() * rect.height())\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "\n",
    "    def findLandmarks(self, rgbImg, bb):\n",
    "       \n",
    "        assert rgbImg is not None\n",
    "        assert bb is not None\n",
    "\n",
    "        points = self.predictor(rgbImg, bb)\n",
    "        return list(map(lambda p: (p.x, p.y), points.parts()))\n",
    "\n",
    "    def align(self, imgDim, rgbImg, bb=None,\n",
    "              landmarks=None, landmarkIndices=INNER_EYES_AND_BOTTOM_LIP,\n",
    "              skipMulti=False):\n",
    "       \n",
    "        assert imgDim is not None\n",
    "        assert rgbImg is not None\n",
    "        assert landmarkIndices is not None\n",
    "\n",
    "        if bb is None:\n",
    "            bb = self.getLargestFaceBoundingBox(rgbImg, skipMulti)\n",
    "            if bb is None:\n",
    "                return\n",
    "\n",
    "        if landmarks is None:\n",
    "            landmarks = self.findLandmarks(rgbImg, bb)\n",
    "\n",
    "        npLandmarks = np.float32(landmarks)\n",
    "        npLandmarkIndices = np.array(landmarkIndices)\n",
    "\n",
    "        H = cv2.getAffineTransform(npLandmarks[npLandmarkIndices],\n",
    "                                   imgDim * MINMAX_TEMPLATE[npLandmarkIndices])\n",
    "        thumbnail = cv2.warpAffine(rgbImg, H, (imgDim, imgDim))\n",
    "\n",
    "        return thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"        \\njc_orig = load_image('./10.JPG')\\n# Detect face and return bounding box\\nbb = alignment.getLargestFaceBoundingBox(jc_orig)\\n\\n# Transform image using specified face landmark indices and crop image to 96x96\\njc_aligned = alignment.align(96, jc_orig, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\\n\\n# Show original image\\nplt.subplot(131)\\nplt.imshow(jc_orig)\\n\\n# Show original image with bounding box\\nplt.subplot(132)\\nplt.imshow(jc_orig)\\nplt.gca().add_patch(patches.Rectangle((bb.left(), bb.top()), bb.width(), bb.height(), fill=False, color='red'))\\n\\n# Show aligned image\\nplt.subplot(133)\\nplt.imshow(jc_aligned);\\n\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "#from AlignDlib import *\n",
    "\n",
    "#from align import AlignDlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]\n",
    "\n",
    "# Initialize the OpenFace face alignment utility\n",
    "#print(\"hello\")\n",
    "alignment = AlignDlib('models/landmarks.dat')\n",
    "\n",
    "# Load an image of Jacques Chirac\n",
    "#jc_orig = load_image(metadata[2].image_path())\n",
    "\n",
    "cwd = os.getcwd()\n",
    "#imageFolders = [x[0] for x in os.walk(cwd + '/aligned')]\n",
    "imageFolders =  os.listdir(cwd + '/aligned')\n",
    "newDir = cwd+'/cropped'\n",
    "if os.path.exists(newDir):\n",
    "    shutil.rmtree(newDir)\n",
    "os.mkdir(newDir)\n",
    "\n",
    "#print(imageFolders)\n",
    "\n",
    "for folder in imageFolders:\n",
    "    #subDir = folder.replace('aligned','cropped')\\\n",
    "    newDir = cwd + '/cropped/' + folder\n",
    "    oldDir = cwd + '/aligned/' + folder\n",
    "    os.mkdir(newDir)\n",
    "    pa = oldDir + '/*'\n",
    "    for filename in glob.glob(pa):\n",
    "        #print(filename)\n",
    "        img = cv2.imread(filename)\n",
    "        bb = alignment.getLargestFaceBoundingBox(img)\n",
    "        cropped = alignment.align(227, img, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "        imgName = filename.replace('aligned', 'cropped')\n",
    "        if bb == None:\n",
    "            cropped = img\n",
    "        #print(imgName)\n",
    "        cv2.imwrite(imgName, cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from align import AlignDlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # OpenCV loads images with color channels\n",
    "    # in BGR order. So we need to reverse them\n",
    "    return img[...,::-1]\n",
    "\n",
    "# Initialize the OpenFace face alignment utility\n",
    "alignment = AlignDlib('models/landmarks.dat')\n",
    "\n",
    "# Load an image of Jacques Chirac\n",
    "jc_orig = load_image(metadata[2].image_path())\n",
    "\n",
    "# Detect face and return bounding box\n",
    "bb = alignment.getLargestFaceBoundingBox(jc_orig)\n",
    "\n",
    "# Transform image using specified face landmark indices and crop image to 96x96\n",
    "jc_aligned = alignment.align(96, jc_orig, bb, landmarkIndices=AlignDlib.OUTER_EYES_AND_NOSE)\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(131)\n",
    "plt.imshow(jc_orig)\n",
    "\n",
    "# Show original image with bounding box\n",
    "plt.subplot(132)\n",
    "plt.imshow(jc_orig)\n",
    "plt.gca().add_patch(patches.Rectangle((bb.left(), bb.top()), bb.width(), bb.height(), fill=False, color='red'))\n",
    "\n",
    "# Show aligned image\n",
    "plt.subplot(133)\n",
    "plt.imshow(jc_aligned);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
